{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ff91206-080e-41e6-bbe5-9c06dee4ff7f",
   "metadata": {},
   "source": [
    "#### Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fbc4a1-9277-472c-a86f-73116aae594e",
   "metadata": {},
   "source": [
    "Polynomial functions and kernel functions are both mathematical tools used in machine learning algorithms, particularly in support vector machines (SVMs) and kernel methods. While they serve different purposes, there is a relationship between them, particularly in the context of SVMs.\n",
    "\n",
    "Polynomial Functions:\n",
    "Polynomial functions are mathematical functions of the form \n",
    "𝑓\n",
    "(\n",
    "𝑥\n",
    ")\n",
    "=\n",
    "𝑎\n",
    "𝑛\n",
    "𝑥\n",
    "𝑛\n",
    "+\n",
    "𝑎\n",
    "𝑛\n",
    "−\n",
    "1\n",
    "𝑥\n",
    "𝑛\n",
    "−\n",
    "1\n",
    "+\n",
    "…\n",
    "+\n",
    "𝑎\n",
    "1\n",
    "𝑥\n",
    "+\n",
    "𝑎\n",
    "0\n",
    "f(x)=a \n",
    "n\n",
    "​\n",
    " x \n",
    "n\n",
    " +a \n",
    "n−1\n",
    "​\n",
    " x \n",
    "n−1\n",
    " +…+a \n",
    "1\n",
    "​\n",
    " x+a \n",
    "0\n",
    "​\n",
    " , where \n",
    "𝑥\n",
    "x is the variable, \n",
    "𝑎\n",
    "𝑖\n",
    "a \n",
    "i\n",
    "​\n",
    "  are coefficients, and \n",
    "𝑛\n",
    "n is a non-negative integer representing the degree of the polynomial. Polynomial functions are used to model relationships between variables in regression and classification tasks. In SVMs, polynomial kernels are used to map the input data into a higher-dimensional feature space.\n",
    "\n",
    "Kernel Functions:\n",
    "Kernel functions in machine learning are mathematical functions that compute the similarity or inner product between pairs of data points in the input space. Kernels enable algorithms to implicitly operate in a higher-dimensional feature space without explicitly computing the transformed feature vectors. Common kernel functions include linear, polynomial, Gaussian (RBF), sigmoid, etc.\n",
    "\n",
    "Relationship:\n",
    "Polynomial functions can be used as kernel functions in SVMs. The polynomial kernel computes the inner product between pairs of data points after mapping them into a higher-dimensional feature space using polynomial functions. Mathematically, the polynomial kernel function is defined as \n",
    "𝐾\n",
    "(\n",
    "𝑥\n",
    "𝑖\n",
    ",\n",
    "𝑥\n",
    "𝑗\n",
    ")\n",
    "=\n",
    "(\n",
    "𝛾\n",
    "𝑥\n",
    "𝑖\n",
    "⋅\n",
    "𝑥\n",
    "𝑗\n",
    "+\n",
    "𝑟\n",
    ")\n",
    "𝑑\n",
    "K(x \n",
    "i\n",
    "​\n",
    " ,x \n",
    "j\n",
    "​\n",
    " )=(γx \n",
    "i\n",
    "​\n",
    " ⋅x \n",
    "j\n",
    "​\n",
    " +r) \n",
    "d\n",
    " , where \n",
    "𝛾\n",
    "γ is a scaling parameter, \n",
    "𝑟\n",
    "r is a coefficient, and \n",
    "𝑑\n",
    "d is the degree of the polynomial.\n",
    "\n",
    "In summary, polynomial functions can be thought of as the basis for polynomial kernel functions in SVMs. The polynomial kernel computes the similarity between data points based on the polynomial transformation of the original input space, enabling SVMs to learn non-linear decision boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87757b34-7d20-4056-a220-e5f616c9594d",
   "metadata": {},
   "source": [
    "#### Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "479b9e73-1536-4981-8a2e-8e2eaa28d410",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create SVM classifier with polynomial kernel\n",
    "svm_classifier = SVC(kernel='poly', degree=3, gamma='scale', coef0=1.0)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels for the testing set\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94390cbc-f7f8-4319-933d-4090e79cecb3",
   "metadata": {},
   "source": [
    "#### Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f492f16-9e74-4d21-bc6a-5406eef2af81",
   "metadata": {},
   "source": [
    "In Support Vector Regression (SVR), epsilon (\n",
    "𝜀\n",
    "ε) is a hyperparameter that defines the width of the epsilon-insensitive tube around the predicted function. The epsilon-insensitive tube determines the range within which errors are not penalized. Data points within this tube are considered correctly predicted and do not contribute to the loss function.\n",
    "\n",
    "Increasing the value of epsilon in SVR affects the number of support vectors in the following way:\n",
    "\n",
    "Wider Tube: Increasing epsilon widens the epsilon-insensitive tube. This means that more data points fall within the tube and are considered correctly predicted. As a result, fewer data points lie on or near the margin boundaries, reducing the number of support vectors.\n",
    "\n",
    "Less Strict Tolerance: A wider epsilon-insensitive tube relaxes the tolerance for errors. SVR allows more errors within the tube without penalizing them, which reduces the necessity for support vectors to capture the training data precisely.\n",
    "\n",
    "Smaller Margin: A wider tube corresponds to a smaller margin between the support vectors and the decision boundary. With a smaller margin, fewer data points are required to define the boundary, leading to fewer support vectors.\n",
    "\n",
    "In summary, increasing the value of epsilon in SVR typically results in a reduction in the number of support vectors because it allows for a wider tolerance for errors and a smaller margin, leading to a looser fit of the model to the training data. However, the exact impact may depend on the specific characteristics of the dataset and the choice of other hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c432e9df-44fe-4d8e-a9e9-6f6ef4da4cae",
   "metadata": {},
   "source": [
    "#### Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a5356a-38f4-4169-9489-7e57ded06b42",
   "metadata": {},
   "source": [
    "Certainly! Let's discuss how the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR), along with examples of when you might want to increase or decrease their values:\n",
    "\n",
    "Kernel Function:\n",
    "\n",
    "The kernel function determines the mapping of the input data into a higher-dimensional space.\n",
    "Common kernel functions include linear, polynomial, Gaussian (RBF), sigmoid, etc.\n",
    "Example:\n",
    "Use a linear kernel if the relationship between input and output is believed to be linear.\n",
    "Use a Gaussian (RBF) kernel for capturing non-linear relationships.\n",
    "C Parameter:\n",
    "\n",
    "The C parameter controls the trade-off between the complexity of the model (decision boundary) and the amount of error allowed in the training data.\n",
    "A smaller C value encourages a larger margin, potentially leading to a simpler model with more training errors.\n",
    "A larger C value results in a narrower margin and possibly overfitting to the training data.\n",
    "Example:\n",
    "Increase C if you want the model to fit the training data more closely (higher complexity).\n",
    "Decrease C if you want to encourage a larger margin and prevent overfitting.\n",
    "Epsilon Parameter:\n",
    "\n",
    "The epsilon parameter (\n",
    "𝜀\n",
    "ε) defines the width of the epsilon-insensitive tube around the predicted function.\n",
    "Data points within this tube are considered correctly predicted and do not contribute to the loss function.\n",
    "A wider epsilon value allows more tolerance for errors.\n",
    "Example:\n",
    "Increase epsilon if you want to allow more tolerance for errors and increase the robustness of the model to noise.\n",
    "Decrease epsilon if you want to penalize errors more strictly and fit the training data more closely.\n",
    "Gamma Parameter:\n",
    "\n",
    "The gamma parameter (\n",
    "𝛾\n",
    "γ) defines the influence of a single training example, affecting the \"smoothness\" of the decision boundary.\n",
    "A small gamma leads to a smoother decision boundary, while a large gamma leads to a more complex, wiggly boundary.\n",
    "For Gaussian (RBF) kernel, \n",
    "𝛾\n",
    "γ determines the spread of the Gaussian function.\n",
    "Example:\n",
    "Increase gamma if you want to capture fine details and create a more complex decision boundary.\n",
    "Decrease gamma if you want to create a smoother decision boundary and avoid overfitting.\n",
    "In summary, each parameter in SVR plays a crucial role in controlling the trade-off between model complexity and generalization, as well as the model's ability to capture non-linear relationships and tolerate errors. Understanding the impact of each parameter and how to adjust them according to the characteristics of the data is essential for optimizing the performance of SVR.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02eb490-7790-4942-867d-392b2a690476",
   "metadata": {},
   "source": [
    "#### L Import the necessary libraries and load the dataseg L Split the dataset into training and testing setZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ebc1906-90bc-48a1-8238-38ebae00584f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (455, 30) (455,)\n",
      "Testing set shape: (114, 30) (114,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Breast Cancer Wisconsin dataset\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "# Split the dataset into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes of the training and testing sets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6d9a6f-aa33-45d9-93eb-c8e7802fe0a7",
   "metadata": {},
   "source": [
    "#### L Preprocess the data using any technique of your choice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46701fea-4d16-4f6b-a372-f866c96d06d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the features in the training set\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Scale the features in the testing set\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c720e5-aa68-467c-a980-d75b7e8a58d7",
   "metadata": {},
   "source": [
    "#### L Create an instance of the SVC classifier and train it on the training datW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b03d6d8-5c65-4e94-acd4-e1ef1f144300",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create an instance of SVC classifier\n",
    "svc_classifier = SVC(kernel='rbf', random_state=42)  # Using the default RBF kernel\n",
    "\n",
    "# Train the classifier on the scaled training data\n",
    "svc_classifier.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5b2e4a-10d8-43d6-8c52-84ed794a1ccc",
   "metadata": {},
   "source": [
    "#### use the trained classifier to predict the labels of the testing datW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf1c90a7-d532-41dd-abf2-eb41c9e6f1ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [1 0 0 1 1 0 0 0 0 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 1 1 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
      " 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Use the trained classifier to predict the labels of the testing data\n",
    "y_pred = svc_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Print the predicted labels\n",
    "print(\"Predicted labels:\", y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53be107-a549-4016-8df9-c56cb0a7a6af",
   "metadata": {},
   "source": [
    "#### L Evaluate the performance of the classifier using any metric of your choice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fbf71a2a-0fcb-4d22-9fd2-193ae1c51991",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9736842105263158\n",
      "Precision: 0.9722222222222222\n",
      "Recall: 0.9859154929577465\n",
      "F1-score: 0.979020979020979\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Compute precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Compute recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Compute F1-score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c4353f-e788-4eae-be9b-6508bfacb35e",
   "metadata": {},
   "source": [
    "#### L Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to improve its performanc_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8dea5828-5586-4334-ab8e-f92ace8b266c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best Hyperparameters: {'C': 10, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "Accuracy of the best estimator: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a grid of hyperparameters\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'gamma': [0.1, 0.01, 0.001, 0.0001],  # Kernel coefficient\n",
    "    'kernel': ['rbf', 'linear', 'poly']  # Kernel function\n",
    "}\n",
    "\n",
    "# Create an instance of SVC classifier\n",
    "svc_classifier = SVC()\n",
    "\n",
    "# Create GridSearchCV instance\n",
    "grid_search = GridSearchCV(svc_classifier, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "# Fit GridSearchCV to the training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Get the best estimator\n",
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best estimator on the testing data\n",
    "y_pred_best = best_estimator.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy of the best estimator\n",
    "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
    "print(\"Accuracy of the best estimator:\", accuracy_best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc089e9-9e71-4999-a497-69622f21dc61",
   "metadata": {},
   "source": [
    "#### L Train the tuned classifier on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4bd47bdd-d034-4f51-87e7-8251ecc10bee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10, gamma=0.1, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, gamma=0.1, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10, gamma=0.1, kernel='linear')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine the entire dataset (features and labels)\n",
    "import numpy as np\n",
    "X_combined = np.vstack((X_train_scaled, X_test_scaled))\n",
    "y_combined = np.concatenate((y_train, y_test))\n",
    "\n",
    "# Create an instance of SVC classifier with the best hyperparameters\n",
    "svc_classifier_tuned = SVC(**best_params)\n",
    "\n",
    "# Train the tuned classifier on the entire dataset\n",
    "svc_classifier_tuned.fit(X_combined, y_combined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1a7cd4-d208-4607-9077-585a530cefe1",
   "metadata": {},
   "source": [
    "#### L Save the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9904381-7b37-4ceb-aab0-ce6acad69a69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained classifier saved to svc_classifier_tuned.joblib\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Specify the filename to save the trained classifier\n",
    "filename = 'svc_classifier_tuned.joblib'\n",
    "\n",
    "# Save the trained classifier to the specified file\n",
    "dump(svc_classifier_tuned, filename)\n",
    "\n",
    "print(\"Trained classifier saved to\", filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5d2f25d-16d6-4045-9404-193992dfb111",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained classifier saved to svc_classifier_tuned.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Specify the filename to save the trained classifier\n",
    "filename = 'svc_classifier_tuned.pkl'\n",
    "\n",
    "# Save the trained classifier to the specified file\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(svc_classifier_tuned, file)\n",
    "\n",
    "print(\"Trained classifier saved to\", filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeb9487-0393-42da-afe2-f1ba7235b952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
